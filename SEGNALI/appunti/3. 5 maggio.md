# QUANTIZZAZIONE
```toc
style: bullet
min_depth: 2
max_depth: 2
```
---
## INTRODUZIONE e GENERALITA'
In generale, sappiamo che nel processo di *campionamento*, si esegue il passaggio:
$$
x(t) \longrightarrow x(nT) \ \in \mathbf{R}
$$
Dato che "ogni campione è un numero reale", ha bisogno di un numero infinito di cifre per essere memorizzato. Pertanto si cerca di **approssimare** questi valori con delle quantità appartenenti a un **alfabeto discreto**. Si cerca cioè di approssimare ogni campione con uno dei possibili livelli (il più vicino) descritti dal range di valori che ho a disposizione nell'alfabeto discreto.
Il valore che subisce questa alterazione viene denominato **quantizzato**, e quindi il processo diventa il seguente:
$$
x(t) \longrightarrow \underbrace{x(nT)}_{\ \in \mathbf{R}} \longrightarrow \underbrace{\hat{x}(nT)}_{\substack{\text{\# finito di cifre} \\ \text{(cifre binarie)}}}
$$
L'errore che si commette quantizzando un campione è **irreversibile**. Non si può infatti "tornare indietro" all'esatto valore di partenza.
Matematicamente si può esprimere in questo modo:
$$
\textestimated(nt) = \hat{x}(nt) - x(nt)
$$
- Viene per questo chiamata **rappresentazione Lossy** ovvero *con perdita*.
- L'errore commesso è modellabile (e rappresentabile) in generale come una **variabile aleatoria**

![[Pasted image 20220509130034.png|250]]

Si passa quindi da un valore $x(nT)$ a $\hat{x}(nT)$ **valore quantizzato**, ovvero:
$$
x(nT) \longrightarrow \hat{x}(nT)
$$
>>**Nota:** **NON** si può effettuare il passaggio inverso, perché non c'è una correlazione $1:1$ ma è piuttosto una correlazione $molti:1$, perciò
$$
x(nT) \xcancel{\longleftarrow} \hat{x}(nT)
$$


La quantizzazione viene quindi effettuata utilizzando **degli intervalli e delle soglie di quantizzazione** (in rosso), e all'interno di ognuno selezioniamo un unico **livello di quantizzazione** (in blu) che sarà il riferimento associativo per tutti i campioni che cadono all'interno del relativo intervallo.
![[Pasted image 20220509131259.png|400]]
*Quantizzare* un segnale significa quindi eseguire il passaggio:
$$
\boxed{x(nT) \quad \stackrel{\text{individuare}}{\longrightarrow } \quad \boxed{\text{intervallo quantizzazione}} \quad \stackrel{\text{associare}}{\longrightarrow } \quad \hat{x}_i \quad con \quad e(nT)}
$$

Da notare che come detto abbiamo **un solo** $\hat x(t)$ per ogni intervallo di quantizzazione, perciò è importante scegliere le soglie e i livelli di quantizzazione per minimizzare l'errore a seconda del segnale d'ingresso.
- Un algoritmo che ci aiuta in questi casi (per ridurre l'errore) è l'**algoritmo di Max-Lloyd** che produce livelli e soglie ottime in relazione alla densità di probabilità dei campioni t.c. la potenza dell'errore sia minima: $$ p_{x(nT)}(x) \rightarrow x_i, \ \hat{x}_i \quad \text{t.c. } E[e^{2}(nT)] \text{ sia minima } $$
- Nota negativa: non facile calcolare intervalli e soglie ottime 

## QUANTIZZATORE UNIFORME
È un quantizzatore ben più semplice rispetto a quanto descritto dall'algoritmo di Max-Lloyd
- Si scelgono **soglie e livelli di quantizzazione equi spaziati**
	- Pertanto, $$ \begin{cases} x_{i}-x_{i-1} = \Delta \\ \hat x_{i}-\hat x_{i-1}=\Delta \end{cases}  \quad \quad \text{con } \Delta = \text{costante} = \text{passo di quantizzazione}$$
	![[Pasted image 20220509134056.png]]

--> Noi sceglieremo i livelli di quantizzazione:
- al centro dell'intervallo (*arrotondamento*): si associa il livello più vicino al valore $x$ da quantizzare. Con questo metodo si commette "meno" errore infatti: $\displaystyle |e| \leq \frac{\Delta}{2}$ (se non c'è overflow, vedi dopo)
- coincidenti con l'estremo sinistro (*troncamento*): associo come livello di quantizzazione la soglia più "piccola" (più a sinistra) che definisce l'intervallo di quantizzazione in cui risiede il valore $x$ da quantizzare. L'errore con questo metodo può essere superiore ($|e| < \Delta$).

![[Pasted image 20220509134354.png|500]]
**Esempio**:
![[Pasted image 20220510145027.png|500]]


> [!example] Segnale Sinusoidale
> ![[Pasted image 20220509135047.png|400]]
> Supponendo la coincidenza [Dinamica - Passo di quantizzazione]:
> $$ \Delta = \frac{D}{2B} $$
> $\Delta$ è quindi: **1)** la distanza tra due livelli ($X$ in blu); **2)** la distanza tra due soglie (liniette rosse)
> La Dinamica del quantizzatore è invece la distanza tra il massimo e il minimo livello di quantizzazione, ovvero l'intervallo di ampiezze che riesco a rappresentare con $B$ bit. Essa sarà evidentemente pari a (formula inversa): $$ D = D_{q} = 2^{B} \cdot \Delta $$

> [!warning] Problemi (e soluzioni) con la Dinamica $D_{q}$
> Può capitare facilmente che un segnale "esca" in maniera evidente dalla Dinamica. Tutti i campioni esterni dalla dinamica subiscono quindi un errore di quantizzazione elevato:
> ![[Pasted image 20220510140023.png|400]]
> I campioni che subiscono un errore rientrano nella situazione di **overflow** (traboccamento)
> > [!done] Attenuatori
> > Una prima soluzione è quella di mantenere la stessa $D_{q}$ ma trovando un modo di ridurre l'ampiezza del segnale. Lo strumento che permette ciò viene detto **attenuatore**. Esso introduce un **guadagno** ( nel nostro caso sarà $<1$ così da ottenere appunto una riduzione) che ci aiuterà ad adattare la dinamica del segnale (cioè "l'ampiezza") a quella del quantizzatore: $$ x(t) \text{ con } D_{s}=(-2;2) \longrightarrow \boxed{Attenuatore \text{ con } G = 1/2} \longrightarrow D_{q}=(-1;1) \ [\dots] \rightarrow \hat{x}(t)  $$
> 
Un altro problema, relativo al *sottoutilizzo* del quantizzatore, è il cosiddetto **underflow**: in questi casi la dinamica del quantizzatore è nettamente maggiore di quella del segnale, il ché comporta in un utilizzo effettivo di pochi livelli di quantizzazione (*rischio di approssimazioni e quindi errore elevato*) 
>![[Pasted image 20220510141652.png|400]] 	
>> [!success] Amplificatore
> In maniera duale rispetto all'attenuatore, con l'amplificatore andiamo ad aumentare la dinamica del segnale così da poter sfruttare a pieno le caratteristiche del quantizzatore (dettate dalla sua dinamica appunto)
> $$ x(t) \text{ con } D_{s}=(0.1;0.1) \longrightarrow \boxed{Amplificatore \text{ con } G = 10} \longrightarrow D_{q}=(-1;1) \rightarrow [\dots] \ \hat{x}(t)  $$

## GESTIONE DEI LIVELLI RISPETTO ALL'ORIGINE
#### MIDRISE
- I livelli sono perfettamente simmetrici rispetto all'origine
![[Pasted image 20220510145917.png|200]]

  #### MIDTREAD
  - I livelli *non* sono perfettamente simmetrici.
  >> L'intervallo di rappresentazione ha la stessa logica per i numeri con segno in complemento a due
- **Include lo zero** nei livelli di quantizzazione.
  
  ![[Pasted image 20220510145746.png|300]]

Con **un numero di bit elevato, la differenza tra i due in valore assoluto è trascurabile**.
- Negli esempi che vedremo utilizzeremo il *midtread* (ha una dinamica praticamente simmetrica rispetto all'origine)

## CARATTERISTICA INPUT/OUTPUT
Vediamo l'andamento relativo alla associazione: 
$$
x \longrightarrow \hat x
$$
Supponiamo di utilizzare un quantitizzatore che lavora seguendo:
- Midtread
- Arrotondamento
- $B = 3$
![[Pasted image 20220510150715.png|400]]

>> da notare che una volta raggiunto il massimo livello rappresentabile, l'associazione prosegue "costantemente", come una linea retta (*quantizzatore saturo*)

## GESTIONE DEI BIT
Se vogliamo in generale ridurre l'errore di approssimazione, dovremmo ridurre il passo di quantizzazione, ovvero $\Delta$, che vale come sappiamo (supponendo per semplicità $D_{s}=D_{q}=D$):
$$
\Delta = \frac{D}{2^{B}}
$$
- La dinamica del segnale è un valore "proveniente dall'esterno", su cui al massimo posso amplificarlo se necessario, ma non posso fare altro per modellare il passo $\Delta$;
- Quello che potenzialmente si può fare è **utilizzare un numero di bit più grande**
	- Ovviamente questa modifica ha un **costo** in termini di memoria
	- L'idea quindi è quella di memorizzare e gestire un segnale con il *numero minimo di bit* per farlo
		- La scelta dei bit di quantizzazione ha un impatto anche sulla trasmissione del segnale stesso: infatti aumentando il numero di bit di quantizzazione aumenta anche il numero di $bit/s$ avere necessariamente sul canale di trasmissione
			- Esempio: $$ CD \quad f_c=44100, \ B = 16\ bit  \longrightarrow 44100 \ campioni/sec \ \text{ ognuno con } 16bit \rightarrow 44100 \cdot 16= 705600 kbit/sec $$
			cioè per memorizzare un secondo di musica sono necessari $700 kbit$ di spazio.
			(poi il cd stereo ha due canali quindi va moltiplicato per due)

## POTENZA DELL'ERRORE DI QUANTIZZAZIONE
L'errore di quantizzazione che si commette a ogni passo $n$ di campionamento, ovvero:
$$
e(nT) = \hat x(nT) - x(nT)
$$
E' modellabile attraverso un **processo aleatorio tempo discreto**.
- Questo anche perché spesso $x(nt)$ è un campionamento di un processo aleatorio
	- In questo modo quindi anche $\hat{x}(nT)$ diventa aleatorio, e quindi anche l'errore è esso stesso un processo aleatorio.

- Anche nel caso di segnali deterministici si preferisce gestire l'errore di quantizzazione come un modello aleatorio (anche se è deterministico, però nella pratica sarebbe più difficile da gestire)

#### $\boxed{\text{IPOTESI DEL MODELLO}}$
#### 1) $e(nT) = e[n]$ è un processo $WSS$
>> - Un processo è $WSS$ tempo discreto se (cfr. appunti): $$E[e[n]] \ costante \ \ e \ \ R_{ee}[n,n+m] = E[e[n] \cdot e[n+m]] = R_{ee}[m]$$
#### 2) $pdf$ di $e[n]$ è uniforme
>> - Errore distribuito in modo uniforme tra un valore minimo e massimo. Nel caso dell'arrotondamento: $$ |e|\leq \frac{\Delta}{2} $$, quindi dato che l'area sottesa dalla $pdf$ deve essere unitaria, otteniamo una retta costante tra $\frac{-\Delta}{2}$ e $\frac{-\Delta}{2}$ di altezza $1/\Delta$. Perciò: $$ p(l) = \begin{cases} \frac{1}{\Delta} & |e| \leq \frac{\Delta}{2} \\ 0 & altrove \end{cases}$$
>> - La media dell'errore vale $$ \mu_{e}= m_{e}= E[e[n]] = E[e] = \int_{-\infty}^{\infty} e \ p(e) \,de  \underbrace{=}_{uniforme} \int_{-\Delta/2}^{\Delta/2} e \ \frac{1}{\Delta} \,de \underbrace{=}_{dispari, \ int \int pari} 0 .$$
>> - La potenza dell'errore vale $$ P_{e}=E[e^{2}[n]] = E[e^{2}] = \int_{-\infty}^{\infty} e^{2 \ p(e) \,de =}\int_{-\Delta/2}^{\Delta/2} e^2 \ \frac{1}{\Delta} \,de \underbrace{=}_{pari} \frac{1}{\Delta} \frac{e^{3}}{3}|^{\Delta/2}_{-\Delta/2} = \frac{\Delta^2}{12}$$ ($\Delta$ piccolo, potenza di errore piccola [proporzionali]). Diminuire il valore ha un costo come visto
#### 3) $e[n]$ è incorrelato con $x[n]$
>> - "Media del prodotto è il prodotto delle medie", ovvero (nel caso di arrotondamento): $$E[e[n]\ x[n]] = \underbrace{E[e[n]]}_{0} \cdot E[x[n]]=0$$
>> - Nota: incorrelatezza implica indipendenza solo quando tutti i processi coinvolti sono gaussiani (non includiamo questa ipotesi)
#### 4) I campioni di $e[n]$ sono incorrelati tra loro
>> Sappiamo che: $$ R_{ee}[m]=E[e[n] \ e[n+m]] = \begin{cases} \underbrace{E[e[n]]}_{0} \cdot \underbrace{E[e[n+m]]}_{0}=0, & m \neq 0 \\ E[e[n]] \cdot E[e[n]] = E[e^2[n]]=\frac{\Delta^2}{12}  ,& m=0 \end{cases} $$, ovvero riassumendo: $$ R_{ee}[m] = \frac{\Delta^2}{12} \cdot \underbrace{\delta[m]}_{\substack{\text{imp. discr.} \\ \text{unitario}}}  $$ ![[Pasted image 20220510163312.png|300]] 
>> Un processo con questa funzione di autocorrelazione viene detto **bianco**, infatti la sua densità spettrale di potenza (ovvero la trasformata di Fourier della funzione di autocorrelazione) è costante (periodica) e vale $\Delta^2/12$.

## SNR: SIGNAL TO NOISE RATIO
Sigla per indicare il *rapporto **segnale-rumore***, ovvero si cerca di valutare le "prestazioni" del segnale sulla base del confronto tra la potenza del segnale che arriva e la potenza del segnale sul ricevitore.
Nel caso di rumore di quantizzazione (ciò che affrontiamo noi), si definisce: 
$$
\boxed{SNR = \frac{S}{P_{e}}} \quad , \quad \text{supponendo: } P_{e}=\frac{\Delta^2}{12}
$$
Dove:
- $S$ è potenza del segnale da quantizzare;
- $P_{e}$ è la potenza dell'errore di quantizzazione.

Sappiamo che $\displaystyle \Delta = \frac{D}{2^{B}}$, dove $D$ è la dinamica sia del segnale che del quantizzatore, supponendo infatti di rientrare in questa ipotesi come già detto precedentemente.
- Sostituendo questa osservazione alla formula dell' $SNR$ precedentemente scritta si ottiene alternativamente:
$$
SNR = \frac{S}{\frac{\Delta^2}{12}} = \frac{S}{\left( \frac{D}{2^{B}} \right)^2 \cdot \frac{1}{12}}
$$
Quindi:
$$
\boxed{\boxed{SNR = \frac{12 \cdot S \cdot 2^{2B}}{D^{2}}}}
$$
- Che è la formula *generale* con la possibilità di "scegliere" la dinamica del segnale e il tipo di segnale a seconda del caso
	- Nella pratica quindi si sostituiscono le informazioni del segnale che conosciamo all'interno della formula

>> Spesso il $SNR$ viene espresso in $d_{B}$ , da cui si ottiene: $$SNR = 10 \log_{10} (SNR) = 10 \log_{10} 2^{2B} + 10 \log_{10} \frac{12 S}{D^{2}}= 2B \cdot 10 \log_{10}2 + 10 \log_{10} \frac{12 S}{D^{2}}$$
>> Da cui finalmente: $$ \boxed{SNR = 6.02B + 10 \log_{10}\frac{12S}{D^{2}} }$$
>> Quindi: *aumentando di una unità il numero di bit, il rapporto segnale rumore (SNR) **migliora** di 6 $dB$* (indipendentemente dal segnale da quantizzare).


## ESEMPI SNR
#### SEGNALE SINUSOIDALE **DETERMINISTICO**
Sia $x(t)$ un segnale della forma:
$$
x(t) = A \ \cos (2\pi f_{0} \ t + \varphi)
$$
Essendo $A$ l'ampiezza del segnale, ne consegue che la relativa *dinamica* sia compresa nell'intervallo $[-A,A]$. Supponiamo la stessa anche per la dinamica del quantizzatore. Riassumendo:
$$
D_{s}= [-A,A] \quad \quad D = 2A
$$
Utilizzando la formula del $SNR$ (precedente) si ottiene:
$$
SNR = 6.02B + 10 \log_{10} \frac{12S}{D^{2}} = 6.02B + 10 \log_{10} \frac{12 \cdot \frac{\cancel{A^2}}{2}}{4\cancel{A^{2}}} = 6.02B + \underbrace{10 \log_{10}\frac{3}{2}}_{1.76}
$$
>> Quindi **nelle ipotesi sulla dinamica appena fatte**, se abbiamo un segnale **sinusoidale** vale la seguente formula: $$ \boxed{SNR = 6.02B + 1.76}$$

#### segnale gaussiano
Un segnale è gaussiano se è un *processo aleatorio* (quindi $x(nT) \text{ sono v.a.}$ distribuite come una gaussiana). Supponiamo anche che abbia media nulla e varianza pari a $\sigma^{2}x$, quindi:
$$
x(t) \rightarrow x(nT) \text{ sono v.a. e } \sim N(0, \sigma^2_{x}) 
$$
In generale quindi un campione ha una distribuzione di probabilità così rappresentata:
![[Pasted image 20220515150833.png|400]]
- Ha una dinamica in teoria compresa nell'intervallo $(-\infty, \infty)$, ovvero illimitata: tuttavia nella pratica *si assume di poter limitare tale intervallo a $[-A,A]$*, infatti oltre tali valori la $pdf$ assume valori trascurabili per l'analisi.
	- Ci si chiede quindi: **come scegliere A**

Per scegliere il valore giusto da scegliere per $A$, bisogna utilizzare delle formule per calcolare la probabilità che un campione con distribuzione gaussiana sia in valore assoluto maggiore di un certo numero di volte ($k$) la deviazione standard, ovvero:
$$
Prob\{|x| > k \cdot \sigma x\}
$$
- La probabilità al crescere di $k$ ovviamente diminuisce, ad esempio:  $$\begin{pmatrix}k=3 \quad \sim 10^{-3} \\ k=4 \quad  \sim 6.3 \cdot 10^{-5} \end{pmatrix}$$
- Quello che è importante adesso quindi è trovare un valore di $k$ adatto, anche se ovviamente non esiste un valore in assoluto perfetto (dipende dall'esperimento)
- Tutti i valori fuori dall'intervallo confinato da $A$ vengono "arrotondati" al valore di $A$.
	- Questo indubbiamente **produce un errore di quantizzazione** (di *overflow*)
		- (Anche se, se scegliamo $k=3$, solo un campione ogni $1000$ esce dall'intervallo; se $k=4$ la probabilità è ancora nettamente più bassa; etc...)
		**- Negli esercizi useremo $k=4$**

Possiamo quindi calcolare $SNR$  (ricordando nel sostituire al'interno della formula che la varianza coincide con la potenza nei segnali gaussiani e supponendo $D = 2A$ e quindi $D = 2 \cdot 4 \sigma$):
$$
SNR = 6.02B + 10 \log_{10}\frac{12\cdot(\cancel{\sigma^2x)}}{(64 \cancel{\sigma^2x)}}
$$
Si conclude quindi:
$$
\boxed{SNR = 6.02B - 7.27} 
$$

## ESERCIZI SNR (cfr. slides)
#### 1) ANALISI: segnale gaussiano (già AFFETTO DA RUMORE)
Si vuole quantizzare il segnale
$$
x(t) + r(t), \quad \quad r(t) = \text{rumore additivo}
$$
Ipotesi $SNR$:
$$
SNR_{\text{ingresso}}=SNR_i = 30dB
$$
Dove:
$$
SNR_i = 30dB = \frac{E[x^2(t)]}{[r^2(t)]}\overbrace{=}^{WSS}P_{x}/R_{r}=\frac{E[x^2[t]]}{E[r^2[t]]}
$$
>>Stesso rapporto tra dominio tempo continuo e dominio tempo discreto

I grafici generali relativi alla densità spettrale sono così rappresentabili:
![[Pasted image 20220515153804.png|350]]

Si utilizza poi un filtro (in blu) per limitare effettivamente la banda (perché idealmente i segnali hanno tutti banda infinita). Esso viene detto *filtro di anti-aliasing* (ideale):
![[Pasted image 20220515153926.png|400]]
>> cfr: "rapporto segnale rumore in ingresso nella banda di interesse" (vuol dire quanto detto sopra)


> [!faq] Ci si chiede quando vale $SNR_{out}$, supponendo $B = 9$ (bit quantizzatore) 
> Ovvero: 
> ![[Pasted image 20220515154443.png|300]]

Può capitare che (è per questi casi che facciamo l'esercizio) $SNR_{out} \neq SNR_{out}$, perché abbiamo due componenti che introducono rumore:
- Uno dovuto a $r[t]$
- Uno dovuto *all'errore di quantizzazione* $e[n]$ dovuto al quantizzatore stesso

Pertanto in uscita avremo i campioni di segnale "utile", cioè $x[n]$ e ognuno di esso è affetto dal campionamento del segnale $r[t]$ e l'errore di quantizzazione $e[n]$
Quindi, ricordando che sarà il quantizzatore ad aggiungere (ulteriore) rumore:
$$
x(t)+r(t)\overbrace{\longrightarrow}^{\text{campionamento}} x[n]+r[n] \overbrace{\longrightarrow}^{\text{quantizzatore}} \underbrace{x[n]+\overbrace{r[n]+e[n]}}^{\quad \quad\text{da rimuovere}}_{\text{uscita}}
$$
Pertanto:
$$
\boxed{SNR_{out}=\frac{P_{x}}{P_{r}+P_e}}
$$
- Nota: le potenze si sommano perché la somma delle potenze è uguale alla potenza della somma, perché l'errore di quantizzazione è *incorrelato* col segnale d'ingresso per ipotesi. DIM (05/04 - h1, m.59):
-  ![[Pasted image 20220515160522.png|300]]

Supponendo (come faremo sempre) $D_{s}=(-1,1)$, dobbiamo all'occorrenza inserire un *guadagno* in ingresso al quantizzatore stesso per adattare la dinamica, che nelle nostre ipotesi sarà pari a $G=1/4\sigma x$:
![[Pasted image 20220515163157.png|400]]
Dove:
- $x'(t)$ e $r'(t)$ sono i segnali dopo il guadagno
- $x'[n]$, $r'[n]$,$e[n]$ sono i segnali sopo la quantizzazione 
![[Pasted image 20220515163456.png|500]]

Ci chiediamo ora se $SNR$ è variato dopo il guadagno, ovvero: $SNR' \neq SNR \ ?$
$$
SNR'=\frac{E[(x'(t))^2]}{E[r'(t)^2]}=\frac{E[(G\cdot x(t))^{2}]}{E[(G\cdot r(t))^{2}]} \underbrace{=}_{G\text{ costante}} = \frac{\cancel G^2 \ E[x^2(t)]}{\cancel G^2 \ E[r^2(t)]}
$$
- E come si nota quindi, il guadagno $G$ (utilizzando un amplificatore ideale) non altera $SNR$ , pertanto:
$$
SNR = SNR' \quad \quad \text{utilizzando un filtro ideale}
$$

Calcoliamo ora per comodità anche la potenza del segnale $x'$, quindi dopo il guadagno (nelle stesse ipotesi):
$$
P_{x'} = E[x'(t)^{2}] = E[ G^2 \ x^2(t) ] = E\left[\left(\frac{1}{4\sigma x}\right)^2 \cdot x^2(t)\right] = \frac{1}{16\sigma x^2} \cdot E[\underbrace{x^2(t)}_{\sigma x^2}] = \frac{1}{16} 
$$

*Andiamo adesso a calcolare $SNR_{out}$* (nota: il segnale è già stato quantizzato quindi si utilizza $x'$):
$$
SNR_{out} = \frac{Px'}{Pr' + P_{e}}, \quad \quad P_{e}=\frac{\Delta^2}{12} = \frac{(\frac{2}{2B})^2}{12} = \frac{4 \cdot 2^{-2B}}{12} = \frac{2^{-2B}}{3}
$$

Pertanto (per comodità si calcola l'inverso):
$$
\frac{1}{SNR_{out}}= \frac{P_{r'}+P_e}{P_{x'}} = \frac{P_{r'}}{P_{x'}} + \frac{P_e}{P_{x'}} = \frac{1}{\underbrace{SNR_{i}}_{30dB \rightarrow 10^3}} + \frac{\overbrace{P_e}^{2^{-2B}/{3}}}{\underbrace{P_{x'}}}_{1/16} $$
Quindi (ricordando che $B = 9$):
$$
SNR_{out} = 29.91 dB \quad \quad \text{(in lineare: } 980.03 \text{)} 
$$

#### 2) progetto: calcolo bit necessari (segnale sinusoidale (con rumore))
Sia $x(t) + r(t)$ il segnale sinusoidale di partenza di riferimento (affetto da rumore).
- Supponiamo quindi $SNR_{i} = 10^3=30dB$

> [!faq] Determina $B \quad \text{t.c. } \Delta_{dB} = 0.1 dB$
> > Dove $\Delta_{dB}$ è la *degradazione* in $dB$ del segnale all'uscita, ovvero $$SNR_{in}-SNR{out} \leq 0.1dB$$
> > Pertanto deve valere: $$SNR_{out} \geq 29.9 dB$$

Ricordando che la dinamica per i segnali *sinusoidali* è pari a $(-A,A)$ e supponendo ancora una volta la dinamica del quantizzatore pari a $(-1,1)$, si ottiene il seguente schema riassuntivo:
![[Pasted image 20220515184634.png|500]]

Il **guadagno** (supponendo al solito di evitare i casi di overflow), sarà (per adattare l'ampiezza (dinamica) del segnale alla dinamica del quantizzatore):
$$
G = \frac{1}{A}
$$
Quindi:
$$
SNR_{out}=\frac{P_{x'}}{P_{r'}+P_e} 
$$
Come abbiamo fatto nell'esercizio precedente:
$$
\frac{1}{SNR_{out}} = \frac{P_{r'}+P_{e}}{P_{x'}} = \underbrace{\frac{P_{r'}}{P_{x'}}}_{1/SNR_i} + \frac{P_{e}}{P_{x'}}
$$
- Da cui, ricordando che $\displaystyle P_{e}= \frac{2^{-2B}}{3}$, andiamo a calcolare $P_{x'}$   :
![[Pasted image 20220515185828.png|500]]
	(controlla perché è così [05/04 2h. 22m.])

Quindi aver adattato la dinamica del segnale alla dinamica del quantizzatore ha prodotto una sinusoide campionata con ampiezza $1$, quindi potenza $\frac{1^2}{2} = \frac{1}{2}$

Ne deriva infine che, sostituendo tutti i dati ottenuti:
$$
B = 7.98 \Rightarrow 8 \ \text{bit}
$$

>> Conti svolti:
>> ![[Pasted image 20220515190329.png|400]]

#### SOMMA DI DUE SINUSOIDI (tipologia: progetto)
Sia $x(t) = s(t)+r(t)$,
con $s(t)$ di *ampiezza unitaria* e pari così esprimibile:
$$
s(t) = cos(2\pi f_{1}t + \varphi_1)+cos(2\pi f_{2}t + \varphi_{2})
$$
Il segnale è tale che:
$$
SNR_{i} = \frac{P_s}{P_{r}}= 60dB
$$
> [!faq] Determina $B$ tale che $\Delta_{dB}<0.5dB$
> (degradazione minore di $0.5dB$)

Dobbiamo ancora introdurre un guadagno $G$ perché il quantizzatore ha dinamica $[-1,1]$
![[Pasted image 20220516092859.png|400]]

**Calcolo di $G$** (riferimento alle ampiezze)
Sommando i due segnali che sono entrambi sinusoidali (ampiezza $1$ per entrambi), si ottiene un qualcosa con dinamica $[-2,2]$, ovvero:
$$
|s(t)| \leq 2
$$
- Dobbiamo quindi introdurre un guadagno $G$ così (semplicemente) definito: $$G = \frac{1}{2}$$
	- Nota: abbiamo tenuto conto *soltanto delle ampiezze per calcolare il guadagno*


**Calcolo della potenza**
Sappiamo che:
$$
Ps' = G^{2} \cdot P_s
$$
Ci si chiede quindi *quanto vale la potenza della somma di due sinusoidi?*
Per varie ragioni (tra cui il fatto che sono due segnali deterministici) conviene utilizzare la *definizione* di potenza media:
$$
\begin{align*}
\overline{P_{s}} &= \lim_{T \to \infty} \frac{1}{T} \ \int_{-T/2}^{T/2} s^{2}(t) \,dt\\
&= \lim_{T \to \infty} \frac{1}{T} \ \left(\int_{-T/2}^{T/2} cos^2(2\pi f_{1}t + \varphi_1)\,dt+\int_{-T/2}^{T/2} cos^2(2\pi f_{2}t + \varphi_2) \,dt+2\int_{-T/2}^{T/2} cos(2\pi f_{1}t + \varphi_1)\cdot cos(2\pi f_{2}t + \varphi_{2}) \,dt \right)
\end{align*}
$$
Concentriamoci sul primo addendo
	Ricordando che:
	$$
	cos^{2}=\frac{1}{2}+\frac{1}{2}\cos (2\pi f_1 t \cdot 2+2\varphi_1)
	$$
	Se integriamo (sfruttando la linearità) rimane qualcosa del tipo:
	$$ \frac{1}{2}T + \frac{1}{2} \int_{-T/2}^{T/2} cos(\dots) \,dt  $$
	Notiamo anche senza calcolare che il coseno integrato diventa un seno quindi una quantità limitata. Dato che poi il tutto è moltiplicato per $\displaystyle \frac{1}{T}$ che tende all'infinito, del primo addendo rimane soltanto (l'integrale si elide): $$ \frac{1}{\cancel T} \cdot \left(\frac{1}{2}\cancel T\right) = \frac{1}{2}  $$
Vale lo stesso per il secondo addendo, ovvero rimane $\displaystyle \frac{1}{2}$
Per il terzo addendo idem, il prodotto tra due coseni per le formule trigonometriche diventa "coseno della somma più coseno della differenza", che integrato diventa "seno della somma più seno della differenza..." che comunque è limitata. Dividendo ancora per $T$ sparisce anche questo termine

Da cui quindi:
$$
\overline{P_{s}}= \frac{1}{2} + \frac{1}{2} = 1
$$
Ovvero la somma di due coseni in potenza porta alla somma delle singole potenze delle due funzioni sinusoidali

*Calcoliamo ora la potenza **dopo** il guadagno*, ovvero:
$$
P_{s'} = G^2 \cdot \left(\frac{1}{2}\right)^2 \cdot 1 = \frac{1}{4}
$$
**Calcolo di SNR**
Calcoliamo il rapporto segnale-rumore all'uscita, ovvero:
$$
SNR_{out}= \frac{P_{s'}}{P_{r'}+P_{e}}
$$
E quindi:
$$
\frac{1}{SNR_{out}} = \frac{P_{r'}+P_{e}}{P_{s'}} = \frac{1}{SNR_{in}}+ \frac{P_e}{P_{s'}}
$$
Ricordando che: $SNR_{in} = 60dB$, $SNR_{out} \geq 59.5dB$, $\displaystyle P_{e} = \frac{2^{-2B}}{3}$ (dinamica $[-1,1]$), $\displaystyle P_{s'}=\frac{1}{4}$
- Rimane una equazione in una incognita $B$

Il risultato è: $$\boxed{B = 11.69dB \Rightarrow 12 \ bit }$$
#### ESERCIZIO FINALE
![[Pasted image 20220516102148.png|550]]
Dove $v_i$, $i=1,2$ indica il rumore
Nelle ipotesi "classiche" (processi stazionari in senso lato, media nulla etc...), sappiamo che:
$$
x_1(t) \text{ è gaussiano, media nulla e varianza (potenza) }4
$$
$$x_2(t) \text{ è gaussiano, media nulla e varianza (potenza)}1$$
Inoltre:
$$
\frac{E[x_1^2(t)]}{E[v_1^2(t)]}=40dB \quad e \quad \frac{E[x_2^2(t)]}{E[v_2^2(t)]}=38dB
$$
- Abbiamo quindi due segnali affetti da due rumori che modificano in maniera diversa la situazione

> [!faq] $SNR_{out}$ utilizzando per quantizzare $10 \ bit$
> 

1°
$$x_{1} \longrightarrow \sigma^{2}_{x_1} = 4 \longrightarrow \sigma_{x_1} =2 \Rightarrow \text{ha dinamica } (-8,8)$$
$$x_{2} \longrightarrow \sigma^{2}_{x_2} = 1 \longrightarrow \sigma_{x_2} =1 \Rightarrow \text{ha dinamica } (-4,4)$$
Il calcolo complessivo della dinamica è dato da:
$$
|x_1(t)+x_2(t)| \leq \underbrace{|x_1(t)|}_{(-8,8)}+\underbrace{|x_2(t)|}_{(-4,4)} \text{ ha dinamica (caso peggiore) } (-12,12)
$$
$\checkmark$ è corretto ma non ottimale (non sfrutto l'ipotesi che sto sommando due segnali gaussiani, che porta ancora a un segnale gaussiano)


Nelle ipotesi "classiche" dei processi si può dimostrare che la potenza complessiva è data dalla somma dei due singoli segnali
- Pertanto, se chiamiamo $x(t) = x_{1}(t) + x_{2}(t)$, allora: $$x(t) \text{ ha potenza (quindi varianza) }4+1 =5$$
Il guadagno che permette di ottenere una situazione di *non* overflow è:
$$
G= \frac{1}{4 \cdot \sqrt{\underbrace{\sigma^2_x}_{\text{dev. standard}}}}=\frac{1}{4\sqrt5}
$$

La potenza dopo il guadagno, ovvero:
$$
P_{x'} = \frac{1}{16}
$$
**Calcolo di $SNR_{out}$**:
![[Pasted image 20220516105851.png|500]]
Da cui:
$$
SNR_{out} = 39.33dB
$$
Apparentemente il rapporto segnale-rumore è maggiore di $38$ che era il minimo dei rapporti segnale-rumore dei segnali di partenza.
- Tuttavia dobbiamo considerare la somma dei due (è ciò che quantizziamo effettivamente)

(controlla per bene: ultimi minuti lezione 05 maggio)


---
