## QUANTIZZAZIONE
In generale, sappiamo che nel processo di *campionamento*, si esegue il passaggio:
$$
x(t) \longrightarrow x(nT) \ \in \mathbf{R}
$$
Dato che "ogni campione è un numero reale", ha bisogno di un numero infinito di cifre per essere memorizzato. Pertanto si cerca di **approssimare** questi valori con delle quantità appartenenti a un **alfabeto discreto**. Si cerca cioè di approssimare ogni campione con uno dei possibili livelli (il più vicino) descritti dal range di valori che ho a disposizione nell'alfabeto discreto.
Il valore che subisce questa alterazione viene denominato **quantizzato**, e quindi il processo diventa il seguente:
$$
x(t) \longrightarrow \underbrace{x(nT)}_{\ \in \mathbf{R}} \longrightarrow \underbrace{\hat{x}(nT)}_{\substack{\text{\# finito di cifre} \\ \text{(cifre binarie)}}}
$$
L'errore che si commette quantizzando un campione è **irreversibile**. Non si può infatti "tornare indietro" all'esatto valore di partenza.
Matematicamente si può esprimere in questo modo:
$$
\textestimated(nt) = \hat{x}(nt) - x(nt)
$$
- Viene per questo chiamata **rappresentazione Lossy** ovvero *con perdita*.
- L'errore commesso è modellabile (e rappresentabile) in generale come una **variabile aleatoria**

![[Pasted image 20220509130034.png|250]]

Si passa quindi da un valore $x(nT)$ a $\hat{x}(nT)$ **valore quantizzato**, ovvero:
$$
x(nT) \longrightarrow \hat{x}(nT)
$$
>>**Nota:** **NON** si può effettuare il passaggio inverso, perché non c'è una correlazione $1:1$ ma è piuttosto una correlazione $molti:1$, perciò
$$
x(nT) \xcancel{\longleftarrow} \hat{x}(nT)
$$


La quantizzazione viene quindi effettuata utilizzando **degli intervalli e delle soglie di quantizzazione** (in rosso), e all'interno di ognuno selezioniamo un unico **livello di quantizzazione** (in blu) che sarà il riferimento associativo per tutti i campioni che cadono all'interno del relativo intervallo.
![[Pasted image 20220509131259.png|400]]
*Quantizzare* un segnale significa quindi eseguire il passaggio:
$$
\boxed{x(nT) \quad \stackrel{\text{individuare}}{\longrightarrow } \quad \boxed{\text{intervallo quantizzazione}} \quad \stackrel{\text{associare}}{\longrightarrow } \quad \hat{x}_i \quad con \quad e(nT)}
$$

Da notare che come detto abbiamo **un solo** $\hat x(t)$ per ogni intervallo di quantizzazione, perciò è importante scegliere le soglie e i livelli di quantizzazione per minimizzare l'errore a seconda del segnale d'ingresso.
- Un algoritmo che ci aiuta in questi casi (per ridurre l'errore) è l'**algoritmo di Max-Lloyd** che produce livelli e soglie ottime in relazione alla densità di probabilità dei campioni t.c. la potenza dell'errore sia minima: $$ p_{x(nT)}(x) \rightarrow x_i, \ \hat{x}_i \quad \text{t.c. } E[e^{2}(nT)] \text{ sia minima } $$
- Nota negativa: non facile calcolare intervalli e soglie ottime 

### QUANTIZZATORE UNIFORME
È un quantizzatore ben più semplice rispetto a quanto descritto dall'algoritmo di Max-Lloyd
- Si scelgono **soglie e livelli di quantizzazione equi spaziati**
	- Pertanto, $$ \begin{cases} x_{i}-x_{i-1} = \Delta \\ \hat x_{i}-\hat x_{i-1}=\Delta \end{cases}  \quad \quad \text{con } \Delta = \text{costante} = \text{passo di quantizzazione}$$
	![[Pasted image 20220509134056.png]]

--> Noi sceglieremo i livelli di quantizzazione:
- al centro dell'intervallo (*arrotondamento*): si associa il livello più vicino al valore $x$ da quantizzare. Con questo metodo si commette "meno" errore infatti: $\displaystyle |e| \leq \frac{\Delta}{2}$ (se non c'è overflow, vedi dopo)
- coincidenti con l'estremo sinistro (*troncamento*): associo come livello di quantizzazione la soglia più "piccola" (più a sinistra) che definisce l'intervallo di quantizzazione in cui risiede il valore $x$ da quantizzare. L'errore con questo metodo può essere superiore ($|e| < \Delta$).

![[Pasted image 20220509134354.png|500]]
**Esempio**:
![[Pasted image 20220510145027.png|500]]


> [!example] Segnale Sinusoidale
> ![[Pasted image 20220509135047.png|400]]
> Supponendo la coincidenza [Dinamica - Passo di quantizzazione]:
> $$ \Delta = \frac{D}{2B} $$
> $\Delta$ è quindi: **1)** la distanza tra due livelli ($X$ in blu); **2)** la distanza tra due soglie (liniette rosse)
> La Dinamica del quantizzatore è invece la distanza tra il massimo e il minimo livello di quantizzazione, ovvero l'intervallo di ampiezze che riesco a rappresentare con $B$ bit. Essa sarà evidentemente pari a (formula inversa): $$ D = D_{q} = 2^{B} \cdot \Delta $$

> [!warning] Problemi (e soluzioni) con la Dinamica $D_{q}$
> Può capitare facilmente che un segnale "esca" in maniera evidente dalla Dinamica. Tutti i campioni esterni dalla dinamica subiscono quindi un errore di quantizzazione elevato:
> ![[Pasted image 20220510140023.png|400]]
> I campioni che subiscono un errore rientrano nella situazione di **overflow** (traboccamento)
> > [!done] Attenuatori
> > Una prima soluzione è quella di mantenere la stessa $D_{q}$ ma trovando un modo di ridurre l'ampiezza del segnale. Lo strumento che permette ciò viene detto **attenuatore**. Esso introduce un **guadagno** ( nel nostro caso sarà $<1$ così da ottenere appunto una riduzione) che ci aiuterà ad adattare la dinamica del segnale (cioè "l'ampiezza") a quella del quantizzatore: $$ x(t) \text{ con } D_{s}=(-2;2) \longrightarrow \boxed{Attenuatore \text{ con } G = 1/2} \longrightarrow D_{q}=(-1;1) \ [\dots] \rightarrow \hat{x}(t)  $$
> 
Un altro problema, relativo al *sottoutilizzo* del quantizzatore, è il cosiddetto **underflow**: in questi casi la dinamica del quantizzatore è nettamente maggiore di quella del segnale, il ché comporta in un utilizzo effettivo di pochi livelli di quantizzazione (*rischio di approssimazioni e quindi errore elevato*) 
>![[Pasted image 20220510141652.png|400]] 	
>> [!success] Amplificatore
> In maniera duale rispetto all'attenuatore, con l'amplificatore andiamo ad aumentare la dinamica del segnale così da poter sfruttare a pieno le caratteristiche del quantizzatore (dettate dalla sua dinamica appunto)
> $$ x(t) \text{ con } D_{s}=(0.1;0.1) \longrightarrow \boxed{Amplificatore \text{ con } G = 10} \longrightarrow D_{q}=(-1;1) \rightarrow [\dots] \ \hat{x}(t)  $$

  ### GESTIONE DEI LIVELLI RISPETTO ALL'ORIGINE

#### MIDRISE
- I livelli sono perfettamente simmetrici rispetto all'origine
![[Pasted image 20220510145917.png|200]]

  #### MIDTREAD
  - I livelli *non* sono perfettamente simmetrici.
  >> L'intervallo di rappresentazione ha la stessa logica per i numeri con segno in complemento a due
- **Include lo zero** nei livelli di quantizzazione.
  
  ![[Pasted image 20220510145746.png|300]]

Con **un numero di bit elevato, la differenza tra i due in valore assoluto è trascurabile**.
- Negli esempi che vedremo utilizzeremo il *midtread* (ha una dinamica praticamente simmetrica rispetto all'origine)

### CARATTERISTICA INPUT/OUTPUT
Vediamo l'andamento relativo alla associazione: 
$$
x \longrightarrow \hat x
$$
Supponiamo di utilizzare un quantitizzatore che lavora seguendo:
- Midtread
- Arrotondamento
- $B = 3$
![[Pasted image 20220510150715.png|400]]

>> da notare che una volta raggiunto il massimo livello rappresentabile, l'associazione prosegue "costantemente", come una linea retta (*quantizzatore saturo*)

### GESTIONE DEI BIT
Se vogliamo in generale ridurre l'errore di approssimazione, dovremmo ridurre il passo di quantizzazione, ovvero $\Delta$, che vale come sappiamo (supponendo per semplicità $D_{s}=D_{q}=D$):
$$
\Delta = \frac{D}{2^{B}}
$$
- La dinamica del segnale è un valore "proveniente dall'esterno", su cui al massimo posso amplificarlo se necessario, ma non posso fare altro per modellare il passo $\Delta$;
- Quello che potenzialmente si può fare è **utilizzare un numero di bit più grande**
	- Ovviamente questa modifica ha un **costo** in termini di memoria
	- L'idea quindi è quella di memorizzare e gestire un segnale con il *numero minimo di bit* per farlo
		- La scelta dei bit di quantizzazione ha un impatto anche sulla trasmissione del segnale stesso: infatti aumentando il numero di bit di quantizzazione aumenta anche il numero di $bit/s$ avere necessariamente sul canale di trasmissione
			- Esempio: $$ CD \quad f_c=44100, \ B = 16\ bit  \longrightarrow 44100 \ campioni/sec \ \text{ ognuno con } 16bit \rightarrow 44100 \cdot 16= 705600 kbit/sec $$
			cioè per memorizzare un secondo di musica sono necessari $700 kbit$ di spazio.
			(poi il cd stereo ha due canali quindi va moltiplicato per due)

### POTENZA DELL'ERRORE DI QUANTIZZAZIONE
L'errore di quantizzazione che si commette a ogni passo $n$ di campionamento, ovvero:
$$
e(nT) = \hat x(nT) - x(nT)
$$
E' modellabile attraverso un **processo aleatorio tempo discreto**.
- Questo anche perché spesso $x(nt)$ è un campionamento di un processo aleatorio
	- In questo modo quindi anche $\hat{x}(nT)$ diventa aleatorio, e quindi anche l'errore è esso stesso un processo aleatorio.

- Anche nel caso di segnali deterministici si preferisce gestire l'errore di quantizzazione come un modello aleatorio (anche se è deterministico, però nella pratica sarebbe più difficile da gestire)

#### $\boxed{\text{IPOTESI DEL MODELLO}}$
#### 1) $e(nT) = e[n]$ è un processo $WSS$
>> - Un processo è $WSS$ tempo discreto se (cfr. appunti): $$E[e[n]] \ costante \ \ e \ \ R_{xx}[n,n+m] = E[e[n] \cdot e[n+m]] = R_{xx}[m]$$
#### 2) $pdf$ di $e[n]$ è uniforme
>> - Errore distribuito in modo uniforme tra un valore minimo e massimo. Nel caso dell'arrotondamento: $$ |e|\leq \frac{\Delta}{2} $$, quindi dato che l'area sottesa dalla $pdf$ deve essere unitaria, otteniamo una retta costante tra $\frac{-\Delta}{2}$ e $\frac{-\Delta}{2}$ di altezza $1/\Delta$. Perciò: $$ p(l) = \begin{cases} \frac{1}{\Delta} & |e| \leq \frac{\Delta}{2} \\ 0 & altrove \end{cases}$$
>> - La media dell'errore vale $$ \mu_{e}= m_{e}= E[e[n]] = E[e] = \int_{-\infty}^{\infty} e \ p(e) \,de  \underbrace{=}_{uniforme} \int_{-\Delta/2}^{\Delta/2} e \ \frac{1}{\Delta} \,de \underbrace{=}_{dispari, \ int \int pari} 0 .$$
>> - La potenza dell'errore vale $$ P_{e}=E[e^{2}[n]] = E[e^{2}] = \int_{-\infty}^{\infty} e^{2 \ p(e) \,de =}\int_{-\Delta/2}^{\Delta/2} e^2 \ \frac{1}{\Delta} \,de \underbrace{=}_{pari} \frac{1}{\Delta} \frac{e^{3}}{3}|^{\Delta/2}_{-\Delta/2} = \frac{\Delta^2}{12}$$ ($\Delta$ piccolo, potenza di errore piccola [proporzionali]). Diminuire il valore ha un costo come visto
#### 3) $e[n]$ è incorrelato con $x[n]$
#### 4) I campioni di $e[n]$ sono incorrelati tra loro


